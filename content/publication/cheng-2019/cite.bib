@inproceedings{cheng2019,
 abstract = {Lane extraction is a basic yet necessary task for autonomous driving. Although past years have witnessed major advances in lane extraction with deep learning models, they all aim at ordinary RGB images generated by framebased cameras, which limits their performance in nature. To tackle this problem, we introduce Dynamic Vision Sensor (DVS), a type of event-based sensor to lane extraction task and build a high-resolution DVS dataset for lane extraction (DET). We collect the raw event data and generate 5,424 event-based sensor images with a resolution of 1280×800, the highest one among all DVS datasets available now. These images include complex trafﬁc scenes and various lane types. All images of DET are annotated with multi-class segmentation format. The fully annotated DET images contains 17,103 lane instances, each of which is labeled pixel by pixel manually. We evaluate state-of-the-art lane extraction models on DET to build a benchmark for lane extraction task with event-based sensor images. Experimental results demonstrate that DET is quite challenging for even state-of-the-art lane extraction methods. DET is made publicly available, including the raw event data, accumulated images and labels1.},
 author = {Cheng, Wensheng and Luo, Hao and Yang, Wen and Yu, Lei and Chen, Shoushun and Li, Wei},
 booktitle = {CVPR Workshops},
 keywords = {Event Camera},
 pages = {10},
 title = {DET: A High-Resolution DVS Dataset for Lane Extraction},
 year = {2019}
}
